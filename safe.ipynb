{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4170cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train\n",
    "env_name = 'mountain_car'\n",
    "train('mountain_car', num_examples=640, mode=1, num_examples_phase2=1, \n",
    "              retrain_phase1=True, retrain_phase2=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df2808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import torch\n",
    "import numpy as np\n",
    "from model_nets import HDNet\n",
    "from torchdiffeq import odeint_adjoint as odeint\n",
    "\n",
    "\n",
    "env_name = \"mountain_car\"\n",
    "num_trajs = 1\n",
    "time_steps = list(np.arange(0, 1.0, 0.05))\n",
    "\n",
    "\n",
    "\n",
    "_, adj_net, hnet, hnet_decoder, _, _ = utils.get_architectures(\n",
    "    arch_file=\"models/architectures.csv\", env_name=env_name\n",
    ")\n",
    "env = utils.get_environment(env_name)\n",
    "adj_net.load_state_dict(torch.load(\"models/\" + env_name + \"/adjoint.pth\"))\n",
    "hnet.load_state_dict(torch.load(\"models/\" + env_name + \"/hamiltonian_dynamics.pth\"))\n",
    "HDnet = HDNet(hnet=hnet)\n",
    "\n",
    "q = torch.tensor(env.sample_q(num_trajs), dtype=torch.float)\n",
    "p = adj_net(q)\n",
    "qp = torch.cat((q, p), axis=1)\n",
    "traj = odeint(HDnet, qp, torch.tensor(time_steps, requires_grad=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87841498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1, 4])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86f74e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4494, -0.0113],\n",
       "        [-0.4356,  0.0160],\n",
       "        [-0.4220,  0.0435],\n",
       "        [-0.4086,  0.0710],\n",
       "        [-0.3955,  0.0986]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj[:5, 0, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52be8ef4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "func must be an instance of nn.Module to specify the adjoint parameters; alternatively they can be specified explicitly via the `adjoint_params` argument. If there are no parameters then it is allowable to set `adjoint_params=()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m     trajectory = odeint(HDNet, qp, torch.tensor(time_steps))\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m trajectory.reshape(-\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m J = \u001b[43mjacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrollout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m env.W_ksi(traj[:,\u001b[32m0\u001b[39m,:\u001b[32m2\u001b[39m], \u001b[32m0.1\u001b[39m).shape\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pml/lib/python3.12/site-packages/torch/autograd/functional.py:677\u001b[39m, in \u001b[36mjacobian\u001b[39m\u001b[34m(func, inputs, create_graph, strict, vectorize, strategy)\u001b[39m\n\u001b[32m    674\u001b[39m is_inputs_tuple, inputs = _as_tuple(inputs, \u001b[33m\"\u001b[39m\u001b[33minputs\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mjacobian\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    675\u001b[39m inputs = _grad_preprocess(inputs, create_graph=create_graph, need_graph=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m677\u001b[39m outputs = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    678\u001b[39m is_outputs_tuple, outputs = _as_tuple(\n\u001b[32m    679\u001b[39m     outputs, \u001b[33m\"\u001b[39m\u001b[33moutputs of the user-provided function\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mjacobian\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    680\u001b[39m )\n\u001b[32m    681\u001b[39m _check_requires_grad(outputs, \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m, strict=strict)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mrollout\u001b[39m\u001b[34m(*param_list)\u001b[39m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m p, new_p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(params, param_list):\n\u001b[32m      8\u001b[39m         p.copy_(new_p)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m trajectory = \u001b[43modeint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mHDNet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_steps\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trajectory.reshape(-\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pml/lib/python3.12/site-packages/torchdiffeq/_impl/adjoint.py:154\u001b[39m, in \u001b[36modeint_adjoint\u001b[39m\u001b[34m(func, y0, t, rtol, atol, method, options, event_fn, adjoint_rtol, adjoint_atol, adjoint_method, adjoint_options, adjoint_params)\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34modeint_adjoint\u001b[39m(func, y0, t, *, rtol=\u001b[32m1e-7\u001b[39m, atol=\u001b[32m1e-9\u001b[39m, method=\u001b[38;5;28;01mNone\u001b[39;00m, options=\u001b[38;5;28;01mNone\u001b[39;00m, event_fn=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    149\u001b[39m                    adjoint_rtol=\u001b[38;5;28;01mNone\u001b[39;00m, adjoint_atol=\u001b[38;5;28;01mNone\u001b[39;00m, adjoint_method=\u001b[38;5;28;01mNone\u001b[39;00m, adjoint_options=\u001b[38;5;28;01mNone\u001b[39;00m, adjoint_params=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    150\u001b[39m \n\u001b[32m    151\u001b[39m     \u001b[38;5;66;03m# We need this in order to access the variables inside this module,\u001b[39;00m\n\u001b[32m    152\u001b[39m     \u001b[38;5;66;03m# since we have no other way of getting variables along the execution path.\u001b[39;00m\n\u001b[32m    153\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m adjoint_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func, nn.Module):\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mfunc must be an instance of nn.Module to specify the adjoint parameters; alternatively they \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    155\u001b[39m                          \u001b[33m'\u001b[39m\u001b[33mcan be specified explicitly via the `adjoint_params` argument. If there are no parameters \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    156\u001b[39m                          \u001b[33m'\u001b[39m\u001b[33mthen it is allowable to set `adjoint_params=()`.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    158\u001b[39m     \u001b[38;5;66;03m# Must come before _check_inputs as we don't want to use normalised input (in particular any changes to options)\u001b[39;00m\n\u001b[32m    159\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m adjoint_rtol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: func must be an instance of nn.Module to specify the adjoint parameters; alternatively they can be specified explicitly via the `adjoint_params` argument. If there are no parameters then it is allowable to set `adjoint_params=()`."
     ]
    }
   ],
   "source": [
    "from torch.autograd.functional import jacobian\n",
    "\n",
    "params = tuple(hnet.parameters()) + tuple(adj_net.parameters())\n",
    "\n",
    "def rollout(*param_list):\n",
    "    with torch.no_grad():\n",
    "        for p, new_p in zip(params, param_list):\n",
    "            p.copy_(new_p)\n",
    "\n",
    "    trajectory = odeint(HDNet, qp, torch.tensor(time_steps))\n",
    "    return trajectory.reshape(-1)\n",
    "\n",
    "J = jacobian(rollout, params, create_graph=False)\n",
    "env.W_ksi(traj[:,0,:2], 0.1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52929334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj[:,0,:2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bb5895",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
